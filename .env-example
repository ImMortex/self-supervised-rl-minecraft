# credentials to use rest api to a server
HTTP_ACCESS_KEY=XXXXX
HTTP_SECRET_KEY=XXXXX
HTTP_BEARER_TOKEN=XXXXX

# credentials for minio server
MINIO_ACCESS_KEY=XXXXX
MINIO_SECRET_KEY=XXXXX

# credentials for Weights and Biases
WANDB_KEY=XXXXX

# for uploading data to minio using minio_upload_sessions_to_s3_storage.py
MINIO_UPLOAD_FROM=D:\_train_a3cMcRlAgent2 # destination on your device were persisted transitions are located
MINIO_UPLOAD_BUCKET_NAME=stcngurs-sessions4 # minio bucket name to which you want to upload

# wandb settings for experiment tracking
WANDB_DIR =./wandb_tmp
WANDB_CACHE_DIR =./wandb_tmp/artifacts/.cache/wandb
WANDB_CONFIG_DIR =./wandb_tmp/config/.cache/wandb
WANDB_MODE=online
WANDB_ENTITY=stcngurs
WANDB_USERNAME=stcngurs

TRAINER_PORT=8080 # only import if using global net on localhost
TRAINER=a3c # only import if using global net on localhost

# pretrain seetings only important if using global net on localhost. The agent uses the config downloaded from the global net on startup.
PRETRAINED_VISION_ENCODER_PATH=pretrainedModels/pretrained_naturecnn_out512_seq1/model/best_model_NatureCNN_state_dict.pt
FREEZE_PRETRAINED_VISION_ENCODER_WEIGHTS=True
UNFREEZE_PRETRAINED_VISION_ENCODER_WEIGHTS=True

# Path to trained classifier to recognize Minecraft items inside players inventory/toolbar to receive RL rewards
PRETRAINED_ICON_CLASSIFIER=pretrainedModels/icon_classifier/2023_09_11__11_20/

# switch between pretraining runs
PRETRAIN_NET_ADDRESS=XXXXX
PRETRAIN_NET_ADDRESS_SIMCLR=XXXXX

# switch between existing global nets. The agent uses the config downloaded from the global net on startup.
XGLOBAL_A3C_NET_ADDRESS=XXXXX
XGLOBAL_A3C_NET_ADDRESS=XXXXX
GLOBAL_A3C_NET_ADDRESS=http://localhost:8080

# Minio server is only needed for pretraining or manual upload of data after RL.
MINIO_ADDRESS=localhost
MINIO_PORT=9000

MINIO_DATASET_TENSOR_CACHE_SIZE=1024000 # number of objects
MINIO_DATASET_TENSOR_CACHE_MAX_AGE=1024000 # in seconds
MINIO_BUCKET_NAME=test-bucket2 #stcngurs-atari-test-ale-breakout-v5 # used bucket for downloads and pretraining
DROPOUT=0.0 # optional dropout for dense layers (increases needed training time for more robust learning)
INPUT_DEPTH=1  # alias state sequence length
IMG_SIZE_H=90 #210 original size for resnet POC amiga # 90 for cnn Minecraft #96 if swin_vit used
IMG_SIZE_W=160 #160 original size for resnet POC amiga # 160 for cnn Minecraft #96 if swin_vit used
CHECKPOINT_WAIT_TIME=0 # set >0 to load existing checkpoints on startup e.g. 3600 to wait for upload using rest API
VISION_ENCODER_OUT_DIM=512
RAM_GB_LIMIT=64 # set limit for pretraining that uses caching
#SCHEDULER=LinearLR # optional: LinearLR
PRETRAIN_ARCHITECTURE=NatureCNN  #resnet18 #resnet50 #NatureCNN #swin_vit
#PRETRAIN_EPOCHS=-1 # only for pretraining SSL Head by Nvidia
PRETRAIN_STEPS=800000 # max steps
PRETRAIN_LEARNING_RATE=5e-5
PRETRAIN_BATCH_SIZE=4
PRETRAIN_MAX_TRAIN_BATCHES = 50000 # >=80. Select batchsize based on existing data so that there is the same amount of data for each seq length considered
PRETRAIN_MAX_VAL_BATCHES = 12500 # >=20. 20 validation steps after 80 training steps each epoch
PRETRAIN_AUGMENTATIONS = ColorJitter,horizontal_shift,vertical_shift #For Minecraft: ColorJitter,horizontal_shift,vertical_shift

FINETUNING_WARMUP_STEPS=51200 # warmup steps only for unfreeze weights using finetuning (freeze + unfreeze weights enabled)
MAX_GLOBAL_NET_STEPS=256000 # max train steps all agents together for RL Minecraft
ACTION_DIM=5 #For Minecraft: 5 #For cartpole POC: 2
MODE=train_a3c #default: "train_a3c", "eval_a3c" for evaluation using "tmp/agent_net/eval/global_net_weights.pth"
DRY_RUN=False # only for debugging one epoch without connection to a global net and without action execution implementation
WORLD_CREATION_MODE=0 # default 0, Choose set of hard coded commands to recreate agents environment

NET_ARCHITECTURE=NatureCNN #resnet18 #resnet50 #NatureCNN #swin_vit
SHOW_POPUPS=False # shows current epoch, step, action ont top of the screen outside of screenshot area

OPTIMIZER=rmsprop # rmsprop used in original A3C paper

AGENT_WORLD_SEED=29 # Minecraft seed (String)
AGENT_STEPS_PER_EPOCH=128
BATCH_SIZE=128 # must be <= AGENT_STEPS_PER_EPOCH
AGENT_CREATE_NEW_WORLD_AFTER_EPOCH=True
AGENT_STEPS_PER_SECOND=0.25 #fps  1/fps = step length. step length = time for destroy block (? sec) + time to collect item (0.5 sec)
AGENT_EPSILON_MAX=0.0 # For greedy exploration. Greedy exploration is not used in original A3C paper
AGENT_EPSILON_MIN=0.0 # For greedy exploration
AGENT_EPSILON_DECAY=0.0005 # For greedy exploration, decay per global net step (=agent epoch)

AGENT_ENTROPY_COEF=0.01 # For exploration according to A3C paper
LEARNING_RATE=7e-4 # RL hyperparameter
AGENT_GAMMA=0.99 # RL hyperparameter


TASK_ITEM_KEY=oak_log # Minecraft item that should be collected. Possible names see: pretrainedModels/icon_classifier/*/class_labels.json
TARGET_SCORE=128 # Define achievable score to use early stopping
EARLY_STOPPING_TOLERANCE=50 # Total number of global net steps (=agent epochs) that reached the target score (with gaps)
LOCAL_GLOBAL_NET=False  # use local global net with only 1 A3C/A2C agent (no network traffic to reduce time between epochs)

PERSIST_TRANSITIONS=True # To persist transitions. You have to upload the transitions to minio server manually to be used for pretraining
AGENT_PERSISTENT_MEMORY_OUT_DIR=D:/ # Use a path with enough space (e.g. >10 GB)

